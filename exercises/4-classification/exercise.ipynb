{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ambwhl/datasci_223/blob/exercise-4/exercises/4-classification/exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0bAkseEHOFq"
      },
      "source": [
        "# Classification on `emnist`\n",
        "\n",
        "## 1. Create `Readme.md` to document your work\n",
        "\n",
        "Explain your choices, process, and outcomes.\n",
        "\n",
        "## 2. Classify all symbols\n",
        "\n",
        "### Choose a model\n",
        "\n",
        "Your choice of model! Choose wisely...\n",
        "\n",
        "### Train away!\n",
        "\n",
        "Is do you need to tune any parameters? Is the model expecting data in a different format?\n",
        "\n",
        "### Evaluate the model\n",
        "\n",
        "Evaluate the models on the test set, analyze the confusion matrix to see where the model performs well and where it struggles.\n",
        "\n",
        "### Investigate subsets\n",
        "\n",
        "On which classes does the model perform well? Poorly? Evaluate again, excluding easily confused symbols (such as 'O' and '0').\n",
        "\n",
        "### Improve performance\n",
        "\n",
        "Brainstorm for improving the performance. This could include trying different architectures, adding more layers, changing the loss function, or using data augmentation techniques.\n",
        "\n",
        "## 2. Classify digits vs. letters model showdown\n",
        "\n",
        "Perform a full showdown classifying digits vs letters:\n",
        "\n",
        "1. Create a column for whether each row is a digit or a letter\n",
        "2. Choose an evaluation metric\n",
        "3. Choose several candidate models to train\n",
        "4. Divide data to reserve a validation set that will NOT be used in training/testing\n",
        "5. K-fold train/test\n",
        "    1. Create train/test splits from the non-validation dataset\n",
        "    2. Train each candidate model (best practice: use the same split for all models)\n",
        "    3. Apply the model the the test split\n",
        "    4. (*Optional*) Perform hyper-parametric search\n",
        "    5. Record the model evaluation metrics\n",
        "    6. Repeat with a new train/test split\n",
        "6. Promote winner, apply model to validation set\n",
        "7. (*Optional*) Perform hyper-parametric search, if applicable\n",
        "8. Report model performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pQr9v8RHOFs"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment and install below packages if not already installed\n",
        "%pip install -q numpy pandas matplotlib seaborn scikit-learn tensorflow emnist xgboost\n"
      ],
      "metadata": {
        "id": "UlXBcHMPIqiD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reset -f"
      ],
      "metadata": {
        "id": "J44O_jwyFdPw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "import os\n",
        "import string\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import emnist\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "# Logistic Regression\n",
        "#from sklearn.linear_model import LogisticRegression\n",
        "#from sklearn.preprocessing import StandardScaler\n",
        "# XGBoost (SVM)\n",
        "#from xgboost import XGBClassifier\n",
        "# Deep Learning\n",
        "#import tensorflow as tf\n",
        "#from tensorflow import keras\n",
        "#from tensorflow.keras.models import Sequential\n",
        "#from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "# Constants\n",
        "SIZE = 28\n",
        "REBUILD = True\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ],
      "metadata": {
        "id": "Fm95JlPUKWq2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##help function\n",
        "def int_to_char(label):\n",
        "    if label < 10:\n",
        "        return str(label)\n",
        "    elif label < 36:\n",
        "        return chr(label - 10 + ord('A'))\n",
        "    else:\n",
        "        return chr(label - 36 + ord('a'))\n",
        "\n",
        "def display_metrics(task, model_name, metrics_dict, class_labels):\n",
        "    \"\"\"Display performance metrics and confusion matrix for a model.\"\"\"\n",
        "    # Assume metrics_dict is a dictionary containing the true labels and predicted labels\n",
        "\n",
        "    # Performance metrics\n",
        "    y_true = metrics_dict[task][model_name]['true']\n",
        "    y_pred = metrics_dict[task][model_name]['pred']\n",
        "\n",
        "    # Calculate the confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=class_labels)\n",
        "    cm_df = pd.DataFrame(cm, index=['actual {}'.format(cls) for cls in class_labels],\n",
        "                         columns=['predicted {}'.format(cls) for cls in class_labels])\n",
        "\n",
        "    # Calculate performance metrics for multi-class\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, average='weighted', labels=class_labels)\n",
        "    rec = recall_score(y_true, y_pred, average='weighted', labels=class_labels)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted', labels=class_labels)\n",
        "\n",
        "    # Performance metrics DataFrame\n",
        "    metrics_df = pd.DataFrame({'Accuracy': [acc], 'Precision': [prec], 'Recall': [rec], 'F1 Score': [f1]})\n",
        "\n",
        "    # Display performance metrics and confusion matrix\n",
        "    display(Markdown(f\"## Performance Metrics: {model_name}\"))\n",
        "    display(metrics_df)\n",
        "    display(Markdown(f\"## Confusion Matrix: {model_name}\"))\n",
        "    display(cm_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "q8NNt6sZNhxN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "digits = list(range(10))\n",
        "uppercase_letters = list(range(10, 36))\n",
        "lowercase_letters = list(range(36, 62))\n",
        "class_labels = digits + uppercase_letters + lowercase_letters\n",
        "assert len(class_labels) == 62"
      ],
      "metadata": {
        "id": "kODyTv--Qz3u"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xBPby4zFI1cP"
      },
      "outputs": [],
      "source": [
        "# Load train data, 16 seconds using T4 GPU provided by google colab\n",
        "image, label = emnist.extract_training_samples('byclass')\n",
        "train = pd.DataFrame()\n",
        "train['image'] = list(image)\n",
        "train['image_flat'] = train['image'].apply(lambda x: np.array(x).reshape(-1))\n",
        "train['label'] = label\n",
        "\n",
        "# Convert labels to characters\n",
        "class_label = np.array([int_to_char(l) for l in label])\n",
        "\n",
        "# Add a column with the character corresponding to the label\n",
        "train['class'] = class_label\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load test set\n",
        "imaget, labelt = emnist.extract_test_samples('byclass')\n",
        "class_labelt = np.array([int_to_char(l) for l in labelt])\n",
        "valid = pd.DataFrame()\n",
        "valid['image'] = list(imaget)\n",
        "valid['image_flat'] = valid['image'].apply(lambda x: np.array(x).reshape(-1))\n",
        "valid['label'] = labelt\n",
        "valid['class'] = class_labelt"
      ],
      "metadata": {
        "id": "sG3rigHLZwlR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_dict = {\n",
        "    'all symbols' : { # task name\n",
        "        'logistic_regression': {\n",
        "            'confusion_matrix': [],\n",
        "            'accuracy': [],\n",
        "            'precision': [],\n",
        "            'recall': [],\n",
        "            'f1': []\n",
        "        },\n",
        "        'xgboost': {\n",
        "            'confusion_matrix': [],\n",
        "            'accuracy': [],\n",
        "            'precision': [],\n",
        "            'recall': [],\n",
        "            'f1': []\n",
        "        },\n",
        "        'random_forest': {\n",
        "            'confusion_matrix': [],\n",
        "            'accuracy': [],\n",
        "            'precision': [],\n",
        "            'recall': [],\n",
        "            'f1': []\n",
        "        },\n",
        "        'neural_network': {\n",
        "            'confusion_matrix': [],\n",
        "            'accuracy': [],\n",
        "            'precision': [],\n",
        "            'recall': [],\n",
        "            'f1': []\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "-h7rZmyB__yU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForest，use T4 GPU provided by google colab，8 min 57sec\n",
        "task = 'all symbols'\n",
        "model_name = 'random_forest'\n",
        "metrics_dict[task] = {model_name: {}}\n",
        "\n",
        "# Initialize random forest classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=50, random_state=42)##n_estimators more than 50 collapses\n",
        "\n",
        "# Train and evaluate model\n",
        "rf_clf.fit(train['image_flat'].tolist(), train['label'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "eR6cS3jiMp1h",
        "outputId": "c564e489-31c3-4c9d-e441-8e67e7e36ea7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=50, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=50, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=50, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rf_clf.predict(valid['image_flat'].tolist())\n",
        "\n",
        "# Calculate performance metrics\n",
        "acc = accuracy_score(valid['label'], y_pred)\n",
        "prec = precision_score(valid['label'], y_pred,average = 'weighted')\n",
        "rec = recall_score(valid['label'], y_pred,average = 'weighted')\n",
        "f1 = f1_score(valid['label'], y_pred,average = 'weighted')\n",
        "cm = confusion_matrix(valid['label'], y_pred)\n",
        "\n",
        "# Store performance metrics in dictionary\n",
        "metrics_dict[task][model_name] = {'accuracy': acc,\n",
        "                                  'precision': prec,\n",
        "                                  'recall': rec,\n",
        "                                  'f1': f1,\n",
        "                                  'confusion_matrix': cm}\n",
        "\n",
        "# Display performance metrics\n",
        "display_metrics(task, model_name, metrics_dict)"
      ],
      "metadata": {
        "id": "qbP_EKSOaCrc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "58731946-1a14-4b1c-92e6-5cdcaf8bb192"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "display_metrics() missing 1 required positional argument: 'class_labels'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-830b79af69e0>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Display performance metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdisplay_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: display_metrics() missing 1 required positional argument: 'class_labels'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}