{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ambwhl/datasci_223/blob/Final-Project/Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0bAkseEHOFq"
      },
      "source": [
        "## Final Project: Kidney Renal Clear Cell Carcinoma (KIRC) Survival prediction and biomarker identification\n",
        "Environment: the whole process in this jupiterbook was conducted on google colab.\n",
        "Description below also can be found in Readme:https://github.com/ambwhl/datasci_223/edit/Final-Project/README.md\n",
        "\n",
        "### Introduction\n",
        "I am intersected in building prognostic prediction model and finding the potential biomarker for cancer patient. The data I used for this project is a subset of kidney renal clear cell carcinoma (KIRC), containing of 243 patients (subjects) and 16380 variables. The variables (predictors) are very rich: clinical covariates (e.g. cancer stage, tumor grade, and survival status), messenger RNA (mRNA) expression, microRNA (miRNA) expression, and copy number variation (CNV).\n",
        "### Strategy and methods\n",
        "1. Dataset was downloaded, combined, and made subset from this public project: https://www.synapse.org/#!Synapse:syn1710282/wiki/27303. Preprocessed data was saved in google drive for further analysis: https://drive.google.com/file/d/1TX0MHLrz51wpUBCalsTpivVnBSFBvIGJ/view?usp=drive_link\n",
        "2. Upon initial data checking, I found several molecular variables with 0 value across all subjects. There variables were considered providing no information hence removed. After cleaning, 15882 variables remained.\n",
        "3. Data set was split to train and test set, 70% in train and 30‚Äù in test. Survival status of subject in 'OS_vital_status' column was extracted as outcome.\n",
        "4. 6 basic models Gradient Boosting, Neural Network, SVM, Decision Tree, Random Forest and kNN were trained and cross-validated in 5- and 10-fold manner. Performance of each model was evaluated as AUC, accuracy, F1-score, precision, and recall. Results shows that Gradient Boosting, SVM and Random Forest have the best performance in both 5-fold and 10-fold cross-validation. These 3 models were used in stacking model for a better prediction power in the next step.\n",
        "5. Top3 models: Gradient Boosting, SVM and Random Forest were stacked and tested its prediction power in test data set. logistic regression was used as the final estimator. The AUC and other performance indicator were greatly improved by stacking model as compared to the basic model: AUC enhanced to 0.813, suggesting prediction power was improved.\n",
        "6. Feature importance generated by the model indicates how crucial a feature (variable) is to the model. As SVM does give out feature importance directly, only feature importance from Gradient Boosting and Random Forest were used to pin down the top 10 variables as potential prognostic biomarkers. It must be noticed that weight of different basic models is difficult and take much careful consideration, so here I just average the feature importance of these 2 models. The top 1 variable with the highest importance is mRNA_PSRC1|84722.\n",
        "###Discussion\n",
        "The top variable is  is a message RNA of gene PSRC1. PSRC1 expressed in several cancers. Notably, it has been established as a prognostic marker in renal cancer (unfavorable) and liver cancer (unfavorable)(Ref.1). The variable ranks the 2nd, which is message RNA of Gene TPX2, is also considered as a prognostic indicator and potential therapeutic target in clear cell renal cell carcinoma (Ref.2). I would say this stacking model, eventhough confined to its samlle sample size (243) and limited population, still shows improved prediction power and strong biomarker identification capacity.\n",
        "###Reference\n",
        "Ref1.https://www.proteinatlas.org/ENSG00000134222-PSRC1/pathology\n",
        "Ref2.https://pubmed.ncbi.nlm.nih.gov/28108243/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pQr9v8RHOFs"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment and install below packages if not already installed\n",
        "#%pip install -q numpy pandas scikit-learn"
      ],
      "metadata": {
        "id": "UlXBcHMPIqiD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## environment requirement\n",
        "%reset -f\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "metadata": {
        "id": "ylrkGNaOHPyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1.Read in preprocessed KIRC survival data\n",
        "file_id = '1TX0MHLrz51wpUBCalsTpivVnBSFBvIGJ'\n",
        "link = f'https://drive.google.com/uc?export=download&id={file_id}'\n",
        "data = pd.read_csv(link)\n",
        "print('subject number:',  len(data.index))\n",
        "print('variable number:',  len(data.columns) - 2) ##minus the \"feature\" (subject index) and 'OS_vital_status' (survival outcome) columns.\n",
        "print('example of variables:', data.columns[1:11])\n"
      ],
      "metadata": {
        "id": "Fm95JlPUKWq2",
        "outputId": "2285919e-67de-4161-e67f-7b63332eebb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "subject number: 243\n",
            "variable number: 16380\n",
            "example of variables: Index(['age', 'gender', 'grade', 'stage', 'OS_vital_status', 'CNV_20q',\n",
            "       'CNV_20p', 'CNV_Xq11.2', 'CNV_14q', 'CNV_17q24.3'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##2. Remove variables with all 0 value\n",
        "missindex=data.columns[(data==0).all()]\n",
        "df= data[missindex]\n",
        "#print(len(df.columns))\n",
        "newdata= data.drop(missindex,axis=1)\n",
        "\n",
        "#print(newdata.columns)\n",
        "newdata = newdata.set_index('feature')\n",
        "for col in ['gender', 'grade', 'stage']:\n",
        "    newdata[col] = newdata[col].astype('category')\n",
        "print(\"variable numbers after cleaning:\",len(newdata.columns)-1)"
      ],
      "metadata": {
        "id": "-UJcs1HpXtZQ",
        "outputId": "c8a0570d-4829-40c7-8d09-18778ef2ed68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "variable numbers after cleaning: 15882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 3. Split to train and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = newdata.drop(columns=['OS_vital_status'])\n",
        "Y = newdata['OS_vital_status']\n",
        "#print(len(Y))\n",
        "#print(len(X.columns))\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "XVyG3Z7gX1Yy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 4. Train and cross-validate basic models\n",
        "# Basic models\n",
        "classifiers = {\n",
        "    'Gradient Boosting': GradientBoostingClassifier(),\n",
        "    #'Logistic Regression': LogisticRegression(),\n",
        "    'Neural Network': MLPClassifier(),\n",
        "    'SVM': SVC(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'kNN': KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "# performance indicator\n",
        "scoring = {\n",
        "    'AUC': 'roc_auc',\n",
        "    'Accuracy': 'accuracy',\n",
        "    'F1 Score': 'f1',\n",
        "    'Precision': 'precision',\n",
        "    'Recall': 'recall'\n",
        "}\n",
        "\n",
        "# 5-fold cross-validation and performance indicator for each model\n",
        "print(\"5-fold cross-validation\")\n",
        "for clf_name, clf in classifiers.items():\n",
        "    print(f\"Evaluation metrics for {clf_name}:\")\n",
        "    for metric_name, scoring_method in scoring.items():\n",
        "        scores = cross_val_score(clf, X_train, Y_train, cv=KFold(n_splits=5, shuffle=True, random_state=42), scoring=scoring_method)\n",
        "        print(f\"{metric_name}: {np.mean(scores):.4f} (std: {np.std(scores):.4f})\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "print(\"\\n\")\n",
        "# 10-fold cross-validation and performance indicator for each model\n",
        "print(\"10-fold cross-validation\")\n",
        "for clf_name, clf in classifiers.items():\n",
        "    print(f\"Evaluation metrics for {clf_name}:\")\n",
        "    for metric_name, scoring_method in scoring.items():\n",
        "        scores = cross_val_score(clf, X_train, Y_train, cv=KFold(n_splits=10, shuffle=True, random_state=42), scoring=scoring_method)\n",
        "        print(f\"{metric_name}: {np.mean(scores):.4f} (std: {np.std(scores):.4f})\")\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "PH1jfW-dX5e4",
        "outputId": "bea46d0e-2924-4bf1-e4e8-f61a5423a670",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5-fold cross-validation\n",
            "Evaluation metrics for Gradient Boosting:\n",
            "AUC: 0.7739 (std: 0.0791)\n",
            "Accuracy: 0.7647 (std: 0.0617)\n",
            "F1 Score: 0.6313 (std: 0.0828)\n",
            "Precision: 0.7371 (std: 0.1413)\n",
            "Recall: 0.6238 (std: 0.1560)\n",
            "\n",
            "\n",
            "Evaluation metrics for Neural Network:\n",
            "AUC: 0.6218 (std: 0.1434)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6412 (std: 0.1267)\n",
            "F1 Score: 0.4353 (std: 0.1722)\n",
            "Precision: 0.5287 (std: 0.1667)\n",
            "Recall: 0.4067 (std: 0.3762)\n",
            "\n",
            "\n",
            "Evaluation metrics for SVM:\n",
            "AUC: 0.6819 (std: 0.0637)\n",
            "Accuracy: 0.6529 (std: 0.0506)\n",
            "F1 Score: 0.2912 (std: 0.1357)\n",
            "Precision: 0.7309 (std: 0.3393)\n",
            "Recall: 0.2195 (std: 0.1525)\n",
            "\n",
            "\n",
            "Evaluation metrics for Decision Tree:\n",
            "AUC: 0.6076 (std: 0.0830)\n",
            "Accuracy: 0.6529 (std: 0.0900)\n",
            "F1 Score: 0.5374 (std: 0.1219)\n",
            "Precision: 0.5220 (std: 0.1266)\n",
            "Recall: 0.5264 (std: 0.1044)\n",
            "\n",
            "\n",
            "Evaluation metrics for Random Forest:\n",
            "AUC: 0.7550 (std: 0.0913)\n",
            "Accuracy: 0.7647 (std: 0.0671)\n",
            "F1 Score: 0.5931 (std: 0.1463)\n",
            "Precision: 0.7300 (std: 0.1600)\n",
            "Recall: 0.5451 (std: 0.1981)\n",
            "\n",
            "\n",
            "Evaluation metrics for kNN:\n",
            "AUC: 0.6097 (std: 0.1224)\n",
            "Accuracy: 0.6412 (std: 0.0681)\n",
            "F1 Score: 0.3193 (std: 0.1763)\n",
            "Precision: 0.5413 (std: 0.3495)\n",
            "Recall: 0.2469 (std: 0.1453)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "10-fold cross-validation\n",
            "Evaluation metrics for Gradient Boosting:\n",
            "AUC: 0.7469 (std: 0.1178)\n",
            "Accuracy: 0.7294 (std: 0.1372)\n",
            "F1 Score: 0.5880 (std: 0.1633)\n",
            "Precision: 0.7150 (std: 0.2340)\n",
            "Recall: 0.5942 (std: 0.2229)\n",
            "\n",
            "\n",
            "Evaluation metrics for Neural Network:\n",
            "AUC: 0.6046 (std: 0.1834)\n",
            "Accuracy: 0.5412 (std: 0.1460)\n",
            "F1 Score: 0.5182 (std: 0.2075)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.3265 (std: 0.2144)\n",
            "Recall: 0.4203 (std: 0.3692)\n",
            "\n",
            "\n",
            "Evaluation metrics for SVM:\n",
            "AUC: 0.7010 (std: 0.1111)\n",
            "Accuracy: 0.6529 (std: 0.1160)\n",
            "F1 Score: 0.2909 (std: 0.2105)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.5875 (std: 0.3955)\n",
            "Recall: 0.2379 (std: 0.2103)\n",
            "\n",
            "\n",
            "Evaluation metrics for Decision Tree:\n",
            "AUC: 0.6084 (std: 0.1455)\n",
            "Accuracy: 0.6471 (std: 0.1488)\n",
            "F1 Score: 0.5071 (std: 0.1544)\n",
            "Precision: 0.5227 (std: 0.2391)\n",
            "Recall: 0.4899 (std: 0.1994)\n",
            "\n",
            "\n",
            "Evaluation metrics for Random Forest:\n",
            "AUC: 0.7786 (std: 0.1217)\n",
            "Accuracy: 0.7706 (std: 0.1034)\n",
            "F1 Score: 0.6561 (std: 0.1142)\n",
            "Precision: 0.8505 (std: 0.2065)\n",
            "Recall: 0.6085 (std: 0.1771)\n",
            "\n",
            "\n",
            "Evaluation metrics for kNN:\n",
            "AUC: 0.5958 (std: 0.1113)\n",
            "Accuracy: 0.6294 (std: 0.1086)\n",
            "F1 Score: 0.2963 (std: 0.1986)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.4917 (std: 0.3698)\n",
            "Recall: 0.2419 (std: 0.1785)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 5. Stack the models with top3 performance\n",
        "# top 3 models\n",
        "gradient_boosting = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
        "svm = make_pipeline(StandardScaler(), SVC(random_state=0))\n",
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "# Stacking\n",
        "stacked_model = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('gradient_boosting', gradient_boosting),\n",
        "        ('svm', svm),\n",
        "        ('random_forest', random_forest)\n",
        "    ],\n",
        "    final_estimator=LogisticRegression()\n",
        ")\n",
        "\n",
        "stacked_model.fit(X_train, Y_train)\n",
        "predictions = stacked_model.predict(X_test)\n",
        "\n",
        "y_proba = stacked_model.predict_proba(X_test)[:, 1]\n",
        "y_pred = stacked_model.predict(X_test)\n",
        "\n",
        "#  performance indicator\n",
        "auc = roc_auc_score(Y_test, y_proba)\n",
        "accuracy = accuracy_score(Y_test, y_pred)\n",
        "f1 = f1_score(Y_test, y_pred)\n",
        "precision = precision_score(Y_test, y_pred)\n",
        "recall = recall_score(Y_test, y_pred)\n",
        "\n",
        "metrics_stacked = {\n",
        "     'AUC': auc,\n",
        "     'Accuracy': accuracy,\n",
        "     'F1 Score': f1,\n",
        "     'Precision': precision,\n",
        "     'Recall': recall\n",
        " }\n",
        "print(metrics_stacked)"
      ],
      "metadata": {
        "id": "dDjBheVPgjXs",
        "outputId": "a2b72939-d4da-4e47-e593-bf9a4daca1b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'AUC': 0.8126984126984127, 'Accuracy': 0.7397260273972602, 'F1 Score': 0.5777777777777777, 'Precision': 0.7647058823529411, 'Recall': 0.4642857142857143}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 6. Pin down biomarkers with top feature importance\n",
        "predictors = X.columns.tolist()\n",
        "\n",
        "#feature importance\n",
        "gb_imp = stacked_model.named_estimators_['gradient_boosting'].feature_importances_\n",
        "rf_imp = stacked_model.named_estimators_['random_forest'].feature_importances_\n",
        "\n",
        "# Average the feature importances as weight\n",
        "imp = (gb_imp + rf_imp) / 2\n",
        "\n",
        "# top 10 variables\n",
        "topind = np.argsort(imp)[::-1][:10]\n",
        "top = [(predictors[i], imp[i]) for i in topind]\n",
        "\n",
        "##show the top variables and their importance, these are the potentail biomarker\n",
        "for feature, importance in top:\n",
        "    print(f\"{feature}: {importance}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkebUESqFL4x",
        "outputId": "accdc1c0-bd4c-4527-f264-949098accb75"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mRNA_PSRC1|84722: 0.16786182986701073\n",
            "mRNA_TPX2|22974: 0.05760733865569538\n",
            "stage: 0.05708578005415763\n",
            "mRNA_NCOR1|9611: 0.037316728895259416\n",
            "mRNA_HK3|3101: 0.02725911232028246\n",
            "mRNA_PMPCA|23203: 0.025781179652827047\n",
            "mRNA_CYP26B1|56603: 0.02566115735037458\n",
            "mRNA_CITED2|10370: 0.02443062193144756\n",
            "miRNA_hsa-mir-335: 0.016659761568937028\n",
            "mRNA_FAM177B|400823: 0.013477700423530253\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}