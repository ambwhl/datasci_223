##Final Project: Build Kidney Renal Clear Cell Carcinoma (KIRC) Survival prediction algarithm and find biomarker using stacking method
Environment: the whole process was conducted on google colab. 
Code and results in jupiterbook:https://colab.research.google.com/github/ambwhl/datasci_223/blob/Final-Project/Final.ipynb#scrollTo=l0bAkseEHOFq

###Introduction
I am intersected in building prognostic prediction model and finding the potential biomarker for cancer patient. The data I used for this project is a subset of kidney renal clear cell carcinoma (KIRC), containing of 243 patients (subjects) and 16380 variables. The variables (predictors) are very rich: clinical covariates (e.g. cancer stage, tumor grade, and survival status), messenger RNA (mRNA) expression, microRNA (miRNA) expression, and copy number variation (CNV).

###Strategy and methods
Dataset was downloaded, combined, and made subset from this public project: https://www.synapse.org/#!Synapse:syn1710282/wiki/27303. Preprocessed data was saved in google drive for further analysis: https://drive.google.com/file/d/1TX0MHLrz51wpUBCalsTpivVnBSFBvIGJ/view?usp=drive_link
Upon initial data checking, I found several molecular variables with 0 value across all subjects. There variables were considered providing no information hence removed. After cleaning, 15882 variables remained.
Data set was split to train and test set, 70% in train and 30‚Äù in test. Survival status of subject in 'OS_vital_status' column was extracted as outcome.
6 basic models Gradient Boosting, Neural Network, SVM, Decision Tree, Random Forest and kNN were trained and cross-validated in 5- and 10-fold manner. Performance of each model was evaluated as AUC, accuracy, F1-score, precision, and recall. Results shows that Gradient Boosting, SVM and Random Forest have the best performance in both 5-fold and 10-fold cross-validation. These 3 models were used in stacking model for a better prediction power in the next step.
Top3 models: Gradient Boosting, SVM and Random Forest were stacked and tested its prediction power in test data set. logistic regression was used as the final estimator. The AUC and other performance indicator were greatly improved by stacking model as compared to the basic model: AUC enhanced to 0.813, suggesting prediction power was improved.
Feature importance generated by the model indicates how crucial a feature (variable) is to the model. As SVM does give out feature importance directly, only feature importance from Gradient Boosting and Random Forest were used to pin down the top 10 variables as potential prognostic biomarkers. It must be noticed that weight of different basic models is difficult and take much careful consideration, so here I just average the feature importance of these 2 models. The top 1 variable with the highest importance is mRNA_PSRC1|84722.
Discussion
The top variable is is a message RNA of gene PSRC1. PSRC1 expressed in several cancers. Notably, it has been established as a prognostic marker in renal cancer (unfavorable) and liver cancer (unfavorable)(Ref.1). The variable ranks the 2nd, which is message RNA of Gene TPX2, is also considered as a prognostic indicator and potential therapeutic target in clear cell renal cell carcinoma (Ref.2). I would say this stacking model, eventhough confined to its small sample size (243) and limited population, still shows improved prediction power and strong biomarker identification capacity.
Reference
Ref1.https://www.proteinatlas.org/ENSG00000134222-PSRC1/pathology Ref2.https://pubmed.ncbi.nlm.nih.gov/28108243/
